{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../datasets/train_weather.csv',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['wnv']=df_train['wnv'].map(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>wetbulb_rolling_14</th>\n",
       "      <th>wetbulb_rolling_14_lag_10</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>dewpoint_rolling_14</th>\n",
       "      <th>dewpoint_rolling_14_lag_10</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmin_rolling_14</th>\n",
       "      <th>tmin_rolling_14_lag_10</th>\n",
       "      <th>tavg</th>\n",
       "      <th>...</th>\n",
       "      <th>preciptotal_rolling_14</th>\n",
       "      <th>preciptotal_rolling_14_lag_7</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>avgspeed_rolling_14</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cool</th>\n",
       "      <th>heat</th>\n",
       "      <th>date</th>\n",
       "      <th>wnv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>58</td>\n",
       "      <td>49.857143</td>\n",
       "      <td>42.214286</td>\n",
       "      <td>60</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>51.571429</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.557143</td>\n",
       "      <td>41.954690</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>58</td>\n",
       "      <td>49.857143</td>\n",
       "      <td>42.214286</td>\n",
       "      <td>60</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>51.571429</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.557143</td>\n",
       "      <td>41.954690</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>58</td>\n",
       "      <td>49.857143</td>\n",
       "      <td>42.214286</td>\n",
       "      <td>60</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>51.571429</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.557143</td>\n",
       "      <td>41.994991</td>\n",
       "      <td>-87.769279</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>58</td>\n",
       "      <td>49.857143</td>\n",
       "      <td>42.214286</td>\n",
       "      <td>60</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>51.571429</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.557143</td>\n",
       "      <td>41.974089</td>\n",
       "      <td>-87.824812</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>58</td>\n",
       "      <td>49.857143</td>\n",
       "      <td>42.214286</td>\n",
       "      <td>60</td>\n",
       "      <td>57.642857</td>\n",
       "      <td>51.571429</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.557143</td>\n",
       "      <td>41.974089</td>\n",
       "      <td>-87.824812</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>58</td>\n",
       "      <td>55.428571</td>\n",
       "      <td>58.785714</td>\n",
       "      <td>52</td>\n",
       "      <td>50.142857</td>\n",
       "      <td>54.428571</td>\n",
       "      <td>55</td>\n",
       "      <td>51.928571</td>\n",
       "      <td>57.357143</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.607143</td>\n",
       "      <td>41.912563</td>\n",
       "      <td>-87.668055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>58</td>\n",
       "      <td>56.214286</td>\n",
       "      <td>58.714286</td>\n",
       "      <td>52</td>\n",
       "      <td>51.142857</td>\n",
       "      <td>54.071429</td>\n",
       "      <td>50</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>57.357143</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.992857</td>\n",
       "      <td>42.009876</td>\n",
       "      <td>-87.807277</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>58</td>\n",
       "      <td>55.428571</td>\n",
       "      <td>58.785714</td>\n",
       "      <td>52</td>\n",
       "      <td>50.142857</td>\n",
       "      <td>54.428571</td>\n",
       "      <td>55</td>\n",
       "      <td>51.928571</td>\n",
       "      <td>57.357143</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.607143</td>\n",
       "      <td>41.776428</td>\n",
       "      <td>-87.627096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>58</td>\n",
       "      <td>56.214286</td>\n",
       "      <td>58.714286</td>\n",
       "      <td>52</td>\n",
       "      <td>51.142857</td>\n",
       "      <td>54.071429</td>\n",
       "      <td>50</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>57.357143</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.992857</td>\n",
       "      <td>41.974689</td>\n",
       "      <td>-87.890615</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>58</td>\n",
       "      <td>56.214286</td>\n",
       "      <td>58.714286</td>\n",
       "      <td>52</td>\n",
       "      <td>51.142857</td>\n",
       "      <td>54.071429</td>\n",
       "      <td>50</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>57.357143</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.992857</td>\n",
       "      <td>41.974689</td>\n",
       "      <td>-87.890615</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8475 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wetbulb  wetbulb_rolling_14  wetbulb_rolling_14_lag_10  dewpoint  \\\n",
       "0          65           58.285714                  53.214286        58   \n",
       "1          65           58.285714                  53.214286        58   \n",
       "2          65           58.285714                  53.214286        58   \n",
       "3          65           58.285714                  53.214286        58   \n",
       "4          65           58.285714                  53.214286        58   \n",
       "...       ...                 ...                        ...       ...   \n",
       "8470       58           55.428571                  58.785714        52   \n",
       "8471       58           56.214286                  58.714286        52   \n",
       "8472       58           55.428571                  58.785714        52   \n",
       "8473       58           56.214286                  58.714286        52   \n",
       "8474       58           56.214286                  58.714286        52   \n",
       "\n",
       "      dewpoint_rolling_14  dewpoint_rolling_14_lag_10  tmin  tmin_rolling_14  \\\n",
       "0               49.857143                   42.214286    60        57.642857   \n",
       "1               49.857143                   42.214286    60        57.642857   \n",
       "2               49.857143                   42.214286    60        57.642857   \n",
       "3               49.857143                   42.214286    60        57.642857   \n",
       "4               49.857143                   42.214286    60        57.642857   \n",
       "...                   ...                         ...   ...              ...   \n",
       "8470            50.142857                   54.428571    55        51.928571   \n",
       "8471            51.142857                   54.071429    50        53.000000   \n",
       "8472            50.142857                   54.428571    55        51.928571   \n",
       "8473            51.142857                   54.071429    50        53.000000   \n",
       "8474            51.142857                   54.071429    50        53.000000   \n",
       "\n",
       "      tmin_rolling_14_lag_10  tavg  ...  preciptotal_rolling_14  \\\n",
       "0                  51.571429    74  ...                0.108571   \n",
       "1                  51.571429    74  ...                0.108571   \n",
       "2                  51.571429    74  ...                0.108571   \n",
       "3                  51.571429    74  ...                0.108571   \n",
       "4                  51.571429    74  ...                0.108571   \n",
       "...                      ...   ...  ...                     ...   \n",
       "8470               57.357143    65  ...                0.001429   \n",
       "8471               57.357143    63  ...                0.001429   \n",
       "8472               57.357143    65  ...                0.001429   \n",
       "8473               57.357143    63  ...                0.001429   \n",
       "8474               57.357143    63  ...                0.001429   \n",
       "\n",
       "      preciptotal_rolling_14_lag_7  avgspeed  avgspeed_rolling_14        lat  \\\n",
       "0                         0.020714       6.5             9.557143  41.954690   \n",
       "1                         0.020714       6.5             9.557143  41.954690   \n",
       "2                         0.020714       6.5             9.557143  41.994991   \n",
       "3                         0.020714       6.5             9.557143  41.974089   \n",
       "4                         0.020714       6.5             9.557143  41.974089   \n",
       "...                            ...       ...                  ...        ...   \n",
       "8470                      0.137143       4.6             7.607143  41.912563   \n",
       "8471                      0.137143       4.2             7.992857  42.009876   \n",
       "8472                      0.137143       4.6             7.607143  41.776428   \n",
       "8473                      0.137143       4.2             7.992857  41.974689   \n",
       "8474                      0.137143       4.2             7.992857  41.974689   \n",
       "\n",
       "           long  cool  heat       date  wnv  \n",
       "0    -87.800991     9     0 2007-05-29    0  \n",
       "1    -87.800991     9     0 2007-05-29    0  \n",
       "2    -87.769279     9     0 2007-05-29    0  \n",
       "3    -87.824812     9     0 2007-05-29    0  \n",
       "4    -87.824812     9     0 2007-05-29    0  \n",
       "...         ...   ...   ...        ...  ...  \n",
       "8470 -87.668055     0     0 2013-09-26    0  \n",
       "8471 -87.807277     0     2 2013-09-26    0  \n",
       "8472 -87.627096     0     0 2013-09-26    0  \n",
       "8473 -87.890615     0     2 2013-09-26    0  \n",
       "8474 -87.890615     0     2 2013-09-26    1  \n",
       "\n",
       "[8475 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['wnv']\n",
    "X=df_train.drop(columns=['wnv','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.946077\n",
       "1    0.053923\n",
       "Name: wnv, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.946201\n",
       "1    0.053799\n",
       "Name: wnv, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "X_train_sc=pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns,index=X_train.index)\n",
    "X_test_sc=pd.DataFrame(ss.transform(X_test),columns=X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>wetbulb_rolling_14</th>\n",
       "      <th>wetbulb_rolling_14_lag_10</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>dewpoint_rolling_14</th>\n",
       "      <th>dewpoint_rolling_14_lag_10</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmin_rolling_14</th>\n",
       "      <th>tmin_rolling_14_lag_10</th>\n",
       "      <th>tavg</th>\n",
       "      <th>...</th>\n",
       "      <th>hz_rolling_14_lag_7</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>preciptotal_rolling_14</th>\n",
       "      <th>preciptotal_rolling_14_lag_7</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>avgspeed_rolling_14</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cool</th>\n",
       "      <th>heat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>-0.804139</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>-0.400908</td>\n",
       "      <td>-0.538605</td>\n",
       "      <td>0.761898</td>\n",
       "      <td>-0.294206</td>\n",
       "      <td>-0.464361</td>\n",
       "      <td>0.195446</td>\n",
       "      <td>-0.596783</td>\n",
       "      <td>-1.143459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>0.032953</td>\n",
       "      <td>1.099194</td>\n",
       "      <td>0.462932</td>\n",
       "      <td>1.751266</td>\n",
       "      <td>-0.481082</td>\n",
       "      <td>0.481207</td>\n",
       "      <td>-1.489587</td>\n",
       "      <td>0.016994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>1.106116</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>-0.356939</td>\n",
       "      <td>1.343886</td>\n",
       "      <td>0.570766</td>\n",
       "      <td>-0.206417</td>\n",
       "      <td>0.964423</td>\n",
       "      <td>0.245425</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1.994650</td>\n",
       "      <td>-0.227543</td>\n",
       "      <td>-0.800310</td>\n",
       "      <td>1.180444</td>\n",
       "      <td>-0.422668</td>\n",
       "      <td>-0.647089</td>\n",
       "      <td>-1.000369</td>\n",
       "      <td>0.912584</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0.224460</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.551745</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.117309</td>\n",
       "      <td>0.684017</td>\n",
       "      <td>-0.074693</td>\n",
       "      <td>-0.129421</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.428529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.838216</td>\n",
       "      <td>-0.605782</td>\n",
       "      <td>-1.290986</td>\n",
       "      <td>-0.933449</td>\n",
       "      <td>0.715979</td>\n",
       "      <td>-1.193483</td>\n",
       "      <td>0.397833</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.545281</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.931060</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.287330</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>-1.530156</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.179521</td>\n",
       "      <td>0.319697</td>\n",
       "      <td>1.084168</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.545281</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.931060</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.287330</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>-1.530156</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.740648</td>\n",
       "      <td>1.566548</td>\n",
       "      <td>1.084168</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>-0.363311</td>\n",
       "      <td>0.167497</td>\n",
       "      <td>-0.459533</td>\n",
       "      <td>-0.538605</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>-0.319289</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.295405</td>\n",
       "      <td>-0.428685</td>\n",
       "      <td>0.166531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.334304</td>\n",
       "      <td>0.103671</td>\n",
       "      <td>1.300029</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>-1.541978</td>\n",
       "      <td>1.895567</td>\n",
       "      <td>0.054666</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>-0.510254</td>\n",
       "      <td>-0.501764</td>\n",
       "      <td>0.405183</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.168278</td>\n",
       "      <td>0.583686</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>-0.641711</td>\n",
       "      <td>0.373012</td>\n",
       "      <td>-1.143459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>2.308095</td>\n",
       "      <td>0.336155</td>\n",
       "      <td>0.361134</td>\n",
       "      <td>0.861550</td>\n",
       "      <td>1.010011</td>\n",
       "      <td>1.118251</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>-1.489587</td>\n",
       "      <td>0.016994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>-1.979681</td>\n",
       "      <td>-1.811806</td>\n",
       "      <td>-1.690653</td>\n",
       "      <td>-1.542600</td>\n",
       "      <td>-1.646365</td>\n",
       "      <td>-1.460549</td>\n",
       "      <td>-1.763255</td>\n",
       "      <td>-1.941177</td>\n",
       "      <td>-1.476064</td>\n",
       "      <td>-2.191451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.227965</td>\n",
       "      <td>-0.210462</td>\n",
       "      <td>0.916109</td>\n",
       "      <td>0.662241</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.478153</td>\n",
       "      <td>-1.489587</td>\n",
       "      <td>2.887774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>-0.069426</td>\n",
       "      <td>0.324132</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>-0.162107</td>\n",
       "      <td>0.430602</td>\n",
       "      <td>0.345401</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>0.245425</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>-0.095467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>0.292477</td>\n",
       "      <td>-1.649742</td>\n",
       "      <td>-0.846243</td>\n",
       "      <td>-1.144875</td>\n",
       "      <td>0.531870</td>\n",
       "      <td>-0.288501</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>1.400001</td>\n",
       "      <td>0.580445</td>\n",
       "      <td>0.214652</td>\n",
       "      <td>1.218386</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.307777</td>\n",
       "      <td>2.003538</td>\n",
       "      <td>0.595282</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.869518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.791242</td>\n",
       "      <td>-0.691603</td>\n",
       "      <td>-0.374165</td>\n",
       "      <td>-0.578394</td>\n",
       "      <td>-1.319915</td>\n",
       "      <td>1.533552</td>\n",
       "      <td>2.285253</td>\n",
       "      <td>-0.341854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6356 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wetbulb  wetbulb_rolling_14  wetbulb_rolling_14_lag_10  dewpoint  \\\n",
       "4903 -0.804139            0.409570                  -0.400908 -0.538605   \n",
       "6913  1.106116            0.409570                  -0.356939  1.343886   \n",
       "1961  0.224460            0.025101                   0.551745  0.088892   \n",
       "907   0.812231            0.694362                   0.141371  0.465390   \n",
       "786   0.812231            0.694362                   0.141371  0.465390   \n",
       "...        ...                 ...                        ...       ...   \n",
       "7607 -0.363311            0.167497                  -0.459533 -0.538605   \n",
       "4235 -0.510254           -0.501764                   0.405183  0.088892   \n",
       "2855 -1.979681           -1.811806                  -1.690653 -1.542600   \n",
       "5920 -0.069426            0.324132                   0.390527 -0.162107   \n",
       "6052  1.400001            0.580445                   0.214652  1.218386   \n",
       "\n",
       "      dewpoint_rolling_14  dewpoint_rolling_14_lag_10      tmin  \\\n",
       "4903             0.761898                   -0.294206 -0.464361   \n",
       "6913             0.570766                   -0.206417  0.964423   \n",
       "1961            -0.117309                    0.684017 -0.074693   \n",
       "907              0.545281                    0.082034  0.704644   \n",
       "786              0.545281                    0.082034  0.704644   \n",
       "...                   ...                         ...       ...   \n",
       "7607             0.201244                   -0.319289  0.704644   \n",
       "4235            -0.168278                    0.583686 -0.334471   \n",
       "2855            -1.646365                   -1.460549 -1.763255   \n",
       "5920             0.430602                    0.345401 -0.334471   \n",
       "6052             0.532539                    0.307777  2.003538   \n",
       "\n",
       "      tmin_rolling_14  tmin_rolling_14_lag_10      tavg  ...  \\\n",
       "4903         0.195446               -0.596783 -1.143459  ...   \n",
       "6913         0.245425                0.023886  0.821526  ...   \n",
       "1961        -0.129421                0.398873  0.428529  ...   \n",
       "907          0.720230                0.243706  0.952525  ...   \n",
       "786          0.720230                0.243706  0.952525  ...   \n",
       "...               ...                     ...       ...  ...   \n",
       "7607         0.295405               -0.428685  0.166531  ...   \n",
       "4235        -0.641711                0.373012 -1.143459  ...   \n",
       "2855        -1.941177               -1.476064 -2.191451  ...   \n",
       "5920         0.245425                0.256637 -0.095467  ...   \n",
       "6052         0.595282                0.114400  1.869518  ...   \n",
       "\n",
       "      hz_rolling_14_lag_7  preciptotal  preciptotal_rolling_14  \\\n",
       "4903            -0.965302    -0.398935                0.032953   \n",
       "6913             0.000152     1.994650               -0.227543   \n",
       "1961            -0.965302    -0.398935               -0.838216   \n",
       "907              1.931060    -0.398935               -0.287330   \n",
       "786              1.931060    -0.398935               -0.287330   \n",
       "...                   ...          ...                     ...   \n",
       "7607            -0.482575    -0.398935               -0.334304   \n",
       "4235            -0.965302     2.308095                0.336155   \n",
       "2855             0.000152    -0.227965               -0.210462   \n",
       "5920            -0.482575    -0.398935                0.255016   \n",
       "6052            -0.965302    -0.398935               -0.791242   \n",
       "\n",
       "      preciptotal_rolling_14_lag_7  avgspeed  avgspeed_rolling_14       lat  \\\n",
       "4903                      1.099194  0.462932             1.751266 -0.481082   \n",
       "6913                     -0.800310  1.180444            -0.422668 -0.647089   \n",
       "1961                     -0.605782 -1.290986            -0.933449  0.715979   \n",
       "907                      -0.205284 -1.530156            -0.759036 -0.179521   \n",
       "786                      -0.205284 -1.530156            -0.759036 -0.740648   \n",
       "...                            ...       ...                  ...       ...   \n",
       "7607                      0.103671  1.300029             0.723475 -1.541978   \n",
       "4235                      0.361134  0.861550             1.010011  1.118251   \n",
       "2855                      0.916109  0.662241             0.038281  0.433451   \n",
       "5920                      0.292477 -1.649742            -0.846243 -1.144875   \n",
       "6052                     -0.691603 -0.374165            -0.578394 -1.319915   \n",
       "\n",
       "          long      cool      heat  \n",
       "4903  0.481207 -1.489587  0.016994  \n",
       "6913 -1.000369  0.912584 -0.341854  \n",
       "1961 -1.193483  0.397833 -0.341854  \n",
       "907   0.319697  1.084168 -0.341854  \n",
       "786   1.566548  1.084168 -0.341854  \n",
       "...        ...       ...       ...  \n",
       "7607  1.895567  0.054666 -0.341854  \n",
       "4235  0.034737 -1.489587  0.016994  \n",
       "2855  0.478153 -1.489587  2.887774  \n",
       "5920  0.531870 -0.288501 -0.341854  \n",
       "6052  1.533552  2.285253 -0.341854  \n",
       "\n",
       "[6356 rows x 49 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_sc_sm,y_train_sm=smote.fit_resample(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe=RFECV(estimator=XGBClassifier(use_label_encoder=False),\n",
    "          step=1,\n",
    "          cv=5,\n",
    "          scoring='roc_auc'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:33:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=5,\n",
       "      estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, gamma=None, gpu_id=None,\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=100,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              random_state=None, reg_alpha=None,\n",
       "                              reg_lambda=None, scale_pos_weight=None,\n",
       "                              subsample=None, tree_method=None,\n",
       "                              use_label_encoder=False, validate_parameters=None,\n",
       "                              verbosity=None),\n",
       "      scoring='roc_auc')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X_train_sc_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc=X_train_sc.loc[:,rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>wetbulb_rolling_14</th>\n",
       "      <th>wetbulb_rolling_14_lag_10</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>dewpoint_rolling_14</th>\n",
       "      <th>dewpoint_rolling_14_lag_10</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmin_rolling_14</th>\n",
       "      <th>tmin_rolling_14_lag_10</th>\n",
       "      <th>tavg</th>\n",
       "      <th>...</th>\n",
       "      <th>hz_rolling_14</th>\n",
       "      <th>hz_rolling_14_lag_7</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>preciptotal_rolling_14</th>\n",
       "      <th>preciptotal_rolling_14_lag_7</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>avgspeed_rolling_14</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>-0.804139</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>-0.400908</td>\n",
       "      <td>-0.538605</td>\n",
       "      <td>0.761898</td>\n",
       "      <td>-0.294206</td>\n",
       "      <td>-0.464361</td>\n",
       "      <td>0.195446</td>\n",
       "      <td>-0.596783</td>\n",
       "      <td>-1.143459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>0.032953</td>\n",
       "      <td>1.099194</td>\n",
       "      <td>0.462932</td>\n",
       "      <td>1.751266</td>\n",
       "      <td>-0.481082</td>\n",
       "      <td>0.481207</td>\n",
       "      <td>-1.489587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>1.106116</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>-0.356939</td>\n",
       "      <td>1.343886</td>\n",
       "      <td>0.570766</td>\n",
       "      <td>-0.206417</td>\n",
       "      <td>0.964423</td>\n",
       "      <td>0.245425</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1.994650</td>\n",
       "      <td>-0.227543</td>\n",
       "      <td>-0.800310</td>\n",
       "      <td>1.180444</td>\n",
       "      <td>-0.422668</td>\n",
       "      <td>-0.647089</td>\n",
       "      <td>-1.000369</td>\n",
       "      <td>0.912584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0.224460</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.551745</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.117309</td>\n",
       "      <td>0.684017</td>\n",
       "      <td>-0.074693</td>\n",
       "      <td>-0.129421</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.428529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.838216</td>\n",
       "      <td>-0.605782</td>\n",
       "      <td>-1.290986</td>\n",
       "      <td>-0.933449</td>\n",
       "      <td>0.715979</td>\n",
       "      <td>-1.193483</td>\n",
       "      <td>0.397833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.545281</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720275</td>\n",
       "      <td>1.931060</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.287330</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>-1.530156</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.179521</td>\n",
       "      <td>0.319697</td>\n",
       "      <td>1.084168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.545281</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720275</td>\n",
       "      <td>1.931060</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.287330</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>-1.530156</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.740648</td>\n",
       "      <td>1.566548</td>\n",
       "      <td>1.084168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>-0.363311</td>\n",
       "      <td>0.167497</td>\n",
       "      <td>-0.459533</td>\n",
       "      <td>-0.538605</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>-0.319289</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.295405</td>\n",
       "      <td>-0.428685</td>\n",
       "      <td>0.166531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.334304</td>\n",
       "      <td>0.103671</td>\n",
       "      <td>1.300029</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>-1.541978</td>\n",
       "      <td>1.895567</td>\n",
       "      <td>0.054666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>-0.510254</td>\n",
       "      <td>-0.501764</td>\n",
       "      <td>0.405183</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.168278</td>\n",
       "      <td>0.583686</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>-0.641711</td>\n",
       "      <td>0.373012</td>\n",
       "      <td>-1.143459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>2.308095</td>\n",
       "      <td>0.336155</td>\n",
       "      <td>0.361134</td>\n",
       "      <td>0.861550</td>\n",
       "      <td>1.010011</td>\n",
       "      <td>1.118251</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>-1.489587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>-1.979681</td>\n",
       "      <td>-1.811806</td>\n",
       "      <td>-1.690653</td>\n",
       "      <td>-1.542600</td>\n",
       "      <td>-1.646365</td>\n",
       "      <td>-1.460549</td>\n",
       "      <td>-1.763255</td>\n",
       "      <td>-1.941177</td>\n",
       "      <td>-1.476064</td>\n",
       "      <td>-2.191451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.227965</td>\n",
       "      <td>-0.210462</td>\n",
       "      <td>0.916109</td>\n",
       "      <td>0.662241</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.478153</td>\n",
       "      <td>-1.489587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>-0.069426</td>\n",
       "      <td>0.324132</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>-0.162107</td>\n",
       "      <td>0.430602</td>\n",
       "      <td>0.345401</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>0.245425</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>-0.095467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>0.292477</td>\n",
       "      <td>-1.649742</td>\n",
       "      <td>-0.846243</td>\n",
       "      <td>-1.144875</td>\n",
       "      <td>0.531870</td>\n",
       "      <td>-0.288501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>1.400001</td>\n",
       "      <td>0.580445</td>\n",
       "      <td>0.214652</td>\n",
       "      <td>1.218386</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.307777</td>\n",
       "      <td>2.003538</td>\n",
       "      <td>0.595282</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.869518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461263</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.791242</td>\n",
       "      <td>-0.691603</td>\n",
       "      <td>-0.374165</td>\n",
       "      <td>-0.578394</td>\n",
       "      <td>-1.319915</td>\n",
       "      <td>1.533552</td>\n",
       "      <td>2.285253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6356 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wetbulb  wetbulb_rolling_14  wetbulb_rolling_14_lag_10  dewpoint  \\\n",
       "4903 -0.804139            0.409570                  -0.400908 -0.538605   \n",
       "6913  1.106116            0.409570                  -0.356939  1.343886   \n",
       "1961  0.224460            0.025101                   0.551745  0.088892   \n",
       "907   0.812231            0.694362                   0.141371  0.465390   \n",
       "786   0.812231            0.694362                   0.141371  0.465390   \n",
       "...        ...                 ...                        ...       ...   \n",
       "7607 -0.363311            0.167497                  -0.459533 -0.538605   \n",
       "4235 -0.510254           -0.501764                   0.405183  0.088892   \n",
       "2855 -1.979681           -1.811806                  -1.690653 -1.542600   \n",
       "5920 -0.069426            0.324132                   0.390527 -0.162107   \n",
       "6052  1.400001            0.580445                   0.214652  1.218386   \n",
       "\n",
       "      dewpoint_rolling_14  dewpoint_rolling_14_lag_10      tmin  \\\n",
       "4903             0.761898                   -0.294206 -0.464361   \n",
       "6913             0.570766                   -0.206417  0.964423   \n",
       "1961            -0.117309                    0.684017 -0.074693   \n",
       "907              0.545281                    0.082034  0.704644   \n",
       "786              0.545281                    0.082034  0.704644   \n",
       "...                   ...                         ...       ...   \n",
       "7607             0.201244                   -0.319289  0.704644   \n",
       "4235            -0.168278                    0.583686 -0.334471   \n",
       "2855            -1.646365                   -1.460549 -1.763255   \n",
       "5920             0.430602                    0.345401 -0.334471   \n",
       "6052             0.532539                    0.307777  2.003538   \n",
       "\n",
       "      tmin_rolling_14  tmin_rolling_14_lag_10      tavg  ...  hz_rolling_14  \\\n",
       "4903         0.195446               -0.596783 -1.143459  ...      -0.991519   \n",
       "6913         0.245425                0.023886  0.821526  ...       0.068993   \n",
       "1961        -0.129421                0.398873  0.428529  ...      -0.991519   \n",
       "907          0.720230                0.243706  0.952525  ...       2.720275   \n",
       "786          0.720230                0.243706  0.952525  ...       2.720275   \n",
       "...               ...                     ...       ...  ...            ...   \n",
       "7607         0.295405               -0.428685  0.166531  ...      -0.991519   \n",
       "4235        -0.641711                0.373012 -1.143459  ...      -0.991519   \n",
       "2855        -1.941177               -1.476064 -2.191451  ...       0.068993   \n",
       "5920         0.245425                0.256637 -0.095467  ...      -0.991519   \n",
       "6052         0.595282                0.114400  1.869518  ...      -0.461263   \n",
       "\n",
       "      hz_rolling_14_lag_7  preciptotal  preciptotal_rolling_14  \\\n",
       "4903            -0.965302    -0.398935                0.032953   \n",
       "6913             0.000152     1.994650               -0.227543   \n",
       "1961            -0.965302    -0.398935               -0.838216   \n",
       "907              1.931060    -0.398935               -0.287330   \n",
       "786              1.931060    -0.398935               -0.287330   \n",
       "...                   ...          ...                     ...   \n",
       "7607            -0.482575    -0.398935               -0.334304   \n",
       "4235            -0.965302     2.308095                0.336155   \n",
       "2855             0.000152    -0.227965               -0.210462   \n",
       "5920            -0.482575    -0.398935                0.255016   \n",
       "6052            -0.965302    -0.398935               -0.791242   \n",
       "\n",
       "      preciptotal_rolling_14_lag_7  avgspeed  avgspeed_rolling_14       lat  \\\n",
       "4903                      1.099194  0.462932             1.751266 -0.481082   \n",
       "6913                     -0.800310  1.180444            -0.422668 -0.647089   \n",
       "1961                     -0.605782 -1.290986            -0.933449  0.715979   \n",
       "907                      -0.205284 -1.530156            -0.759036 -0.179521   \n",
       "786                      -0.205284 -1.530156            -0.759036 -0.740648   \n",
       "...                            ...       ...                  ...       ...   \n",
       "7607                      0.103671  1.300029             0.723475 -1.541978   \n",
       "4235                      0.361134  0.861550             1.010011  1.118251   \n",
       "2855                      0.916109  0.662241             0.038281  0.433451   \n",
       "5920                      0.292477 -1.649742            -0.846243 -1.144875   \n",
       "6052                     -0.691603 -0.374165            -0.578394 -1.319915   \n",
       "\n",
       "          long      cool  \n",
       "4903  0.481207 -1.489587  \n",
       "6913 -1.000369  0.912584  \n",
       "1961 -1.193483  0.397833  \n",
       "907   0.319697  1.084168  \n",
       "786   1.566548  1.084168  \n",
       "...        ...       ...  \n",
       "7607  1.895567  0.054666  \n",
       "4235  0.034737 -1.489587  \n",
       "2855  0.478153 -1.489587  \n",
       "5920  0.531870 -0.288501  \n",
       "6052  1.533552  2.285253  \n",
       "\n",
       "[6356 rows x 45 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc=X_test_sc[X_train_sc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>wetbulb_rolling_14</th>\n",
       "      <th>wetbulb_rolling_14_lag_10</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>dewpoint_rolling_14</th>\n",
       "      <th>dewpoint_rolling_14_lag_10</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmin_rolling_14</th>\n",
       "      <th>tmin_rolling_14_lag_10</th>\n",
       "      <th>tavg</th>\n",
       "      <th>...</th>\n",
       "      <th>hz_rolling_14</th>\n",
       "      <th>hz_rolling_14_lag_7</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>preciptotal_rolling_14</th>\n",
       "      <th>preciptotal_rolling_14_lag_7</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>avgspeed_rolling_14</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>0.959173</td>\n",
       "      <td>1.676893</td>\n",
       "      <td>1.533710</td>\n",
       "      <td>1.092887</td>\n",
       "      <td>1.717557</td>\n",
       "      <td>1.474120</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>1.444933</td>\n",
       "      <td>1.510905</td>\n",
       "      <td>0.559528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.535015</td>\n",
       "      <td>0.721582</td>\n",
       "      <td>-0.613336</td>\n",
       "      <td>-1.238672</td>\n",
       "      <td>-1.319915</td>\n",
       "      <td>1.533552</td>\n",
       "      <td>0.569417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.545281</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.720230</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.952525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720275</td>\n",
       "      <td>1.931060</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.287330</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>-1.530156</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.220125</td>\n",
       "      <td>0.795337</td>\n",
       "      <td>1.084168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>0.224460</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.551745</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.117309</td>\n",
       "      <td>0.684017</td>\n",
       "      <td>-0.074693</td>\n",
       "      <td>-0.129421</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.428529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.838216</td>\n",
       "      <td>-0.605782</td>\n",
       "      <td>-1.290986</td>\n",
       "      <td>-0.933449</td>\n",
       "      <td>0.938662</td>\n",
       "      <td>-1.640036</td>\n",
       "      <td>0.397833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>-1.098024</td>\n",
       "      <td>-0.516004</td>\n",
       "      <td>-0.210377</td>\n",
       "      <td>-0.915103</td>\n",
       "      <td>-0.881837</td>\n",
       "      <td>-0.319289</td>\n",
       "      <td>-0.724140</td>\n",
       "      <td>-0.166906</td>\n",
       "      <td>-0.118351</td>\n",
       "      <td>-1.143459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461263</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>0.246476</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>1.140582</td>\n",
       "      <td>0.922804</td>\n",
       "      <td>-0.182266</td>\n",
       "      <td>-0.378025</td>\n",
       "      <td>-1.489587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>1.546944</td>\n",
       "      <td>0.124778</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>1.469385</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.433191</td>\n",
       "      <td>0.964423</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.230775</td>\n",
       "      <td>1.214523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.965302</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.791242</td>\n",
       "      <td>-0.342598</td>\n",
       "      <td>-0.653197</td>\n",
       "      <td>-0.989511</td>\n",
       "      <td>1.376284</td>\n",
       "      <td>-0.622362</td>\n",
       "      <td>1.427335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.224460</td>\n",
       "      <td>-0.273931</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.435863</td>\n",
       "      <td>0.194905</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>-0.066947</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>0.559528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.461263</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.398935</td>\n",
       "      <td>-0.765619</td>\n",
       "      <td>0.956159</td>\n",
       "      <td>-0.214718</td>\n",
       "      <td>-0.466271</td>\n",
       "      <td>-1.319915</td>\n",
       "      <td>1.533552</td>\n",
       "      <td>0.569417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>0.371403</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.738000</td>\n",
       "      <td>0.590890</td>\n",
       "      <td>-0.346668</td>\n",
       "      <td>-0.620280</td>\n",
       "      <td>-0.074693</td>\n",
       "      <td>-0.291854</td>\n",
       "      <td>-0.351102</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.170975</td>\n",
       "      <td>-0.535015</td>\n",
       "      <td>-0.703046</td>\n",
       "      <td>-1.051815</td>\n",
       "      <td>-1.637331</td>\n",
       "      <td>1.534988</td>\n",
       "      <td>-0.988416</td>\n",
       "      <td>-0.116918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0.665288</td>\n",
       "      <td>0.822518</td>\n",
       "      <td>0.243965</td>\n",
       "      <td>0.967388</td>\n",
       "      <td>1.271583</td>\n",
       "      <td>0.408108</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.657756</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.297530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.170966</td>\n",
       "      <td>3.675639</td>\n",
       "      <td>2.529543</td>\n",
       "      <td>-0.095133</td>\n",
       "      <td>-0.055155</td>\n",
       "      <td>-1.161051</td>\n",
       "      <td>0.554517</td>\n",
       "      <td>0.226250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.812231</td>\n",
       "      <td>-0.060337</td>\n",
       "      <td>0.097403</td>\n",
       "      <td>1.092887</td>\n",
       "      <td>-0.181020</td>\n",
       "      <td>0.144740</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>0.132971</td>\n",
       "      <td>0.127331</td>\n",
       "      <td>0.559528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599250</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.085481</td>\n",
       "      <td>-0.304411</td>\n",
       "      <td>0.692975</td>\n",
       "      <td>0.144038</td>\n",
       "      <td>-0.977052</td>\n",
       "      <td>1.448658</td>\n",
       "      <td>-1.198295</td>\n",
       "      <td>0.569417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.665288</td>\n",
       "      <td>0.722841</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.967388</td>\n",
       "      <td>1.105935</td>\n",
       "      <td>0.458273</td>\n",
       "      <td>0.704644</td>\n",
       "      <td>0.607776</td>\n",
       "      <td>0.424734</td>\n",
       "      <td>0.297530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>0.284946</td>\n",
       "      <td>3.590231</td>\n",
       "      <td>2.764120</td>\n",
       "      <td>-0.174856</td>\n",
       "      <td>-0.048926</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>-0.970165</td>\n",
       "      <td>0.226250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2119 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wetbulb  wetbulb_rolling_14  wetbulb_rolling_14_lag_10  dewpoint  \\\n",
       "5602  0.959173            1.676893                   1.533710  1.092887   \n",
       "792   0.812231            0.694362                   0.141371  0.465390   \n",
       "1935  0.224460            0.025101                   0.551745  0.088892   \n",
       "3580 -1.098024           -0.516004                  -0.210377 -0.915103   \n",
       "5991  1.546944            0.124778                   0.331902  1.469385   \n",
       "...        ...                 ...                        ...       ...   \n",
       "572   0.224460           -0.273931                   0.199996  0.088892   \n",
       "3408  0.371403           -0.359368                  -0.738000  0.590890   \n",
       "1825  0.665288            0.822518                   0.243965  0.967388   \n",
       "641   0.812231           -0.060337                   0.097403  1.092887   \n",
       "1723  0.665288            0.722841                   0.331902  0.967388   \n",
       "\n",
       "      dewpoint_rolling_14  dewpoint_rolling_14_lag_10      tmin  \\\n",
       "5602             1.717557                    1.474120  0.834534   \n",
       "792              0.545281                    0.082034  0.704644   \n",
       "1935            -0.117309                    0.684017 -0.074693   \n",
       "3580            -0.881837                   -0.319289 -0.724140   \n",
       "5991             0.112049                    0.433191  0.964423   \n",
       "...                   ...                         ...       ...   \n",
       "572             -0.435863                    0.194905  0.834534   \n",
       "3408            -0.346668                   -0.620280 -0.074693   \n",
       "1825             1.271583                    0.408108  0.704644   \n",
       "641             -0.181020                    0.144740  0.834534   \n",
       "1723             1.105935                    0.458273  0.704644   \n",
       "\n",
       "      tmin_rolling_14  tmin_rolling_14_lag_10      tavg  ...  hz_rolling_14  \\\n",
       "5602         1.444933                1.510905  0.559528  ...       0.068993   \n",
       "792          0.720230                0.243706  0.952525  ...       2.720275   \n",
       "1935        -0.129421                0.398873  0.428529  ...      -0.991519   \n",
       "3580        -0.166906               -0.118351 -1.143459  ...      -0.461263   \n",
       "5991         0.045507                0.230775  1.214523  ...      -0.991519   \n",
       "...               ...                     ...       ...  ...            ...   \n",
       "572         -0.066947                0.243706  0.559528  ...      -0.461263   \n",
       "3408        -0.291854               -0.351102  0.035532  ...       0.068993   \n",
       "1825         0.657756                0.347151  0.297530  ...       0.068993   \n",
       "641          0.132971                0.127331  0.559528  ...       0.599250   \n",
       "1723         0.607776                0.424734  0.297530  ...       0.068993   \n",
       "\n",
       "      hz_rolling_14_lag_7  preciptotal  preciptotal_rolling_14  \\\n",
       "5602            -0.482575    -0.398935               -0.535015   \n",
       "792              1.931060    -0.398935               -0.287330   \n",
       "1935            -0.965302    -0.398935               -0.838216   \n",
       "3580             0.000152    -0.398935                0.246476   \n",
       "5991            -0.965302    -0.398935               -0.791242   \n",
       "...                   ...          ...                     ...   \n",
       "572              0.000152    -0.398935               -0.765619   \n",
       "3408             0.000152    -0.170975               -0.535015   \n",
       "1825             0.000152     0.170966                3.675639   \n",
       "641              0.000152     0.085481               -0.304411   \n",
       "1723            -0.482575     0.284946                3.590231   \n",
       "\n",
       "      preciptotal_rolling_14_lag_7  avgspeed  avgspeed_rolling_14       lat  \\\n",
       "5602                      0.721582 -0.613336            -1.238672 -1.319915   \n",
       "792                      -0.205284 -1.530156            -0.759036 -0.220125   \n",
       "1935                     -0.605782 -1.290986            -0.933449  0.938662   \n",
       "3580                      0.086507  1.140582             0.922804 -0.182266   \n",
       "5991                     -0.342598 -0.653197            -0.989511  1.376284   \n",
       "...                            ...       ...                  ...       ...   \n",
       "572                       0.956159 -0.214718            -0.466271 -1.319915   \n",
       "3408                     -0.703046 -1.051815            -1.637331  1.534988   \n",
       "1825                      2.529543 -0.095133            -0.055155 -1.161051   \n",
       "641                       0.692975  0.144038            -0.977052  1.448658   \n",
       "1723                      2.764120 -0.174856            -0.048926  0.912768   \n",
       "\n",
       "          long      cool  \n",
       "5602  1.533552  0.569417  \n",
       "792   0.795337  1.084168  \n",
       "1935 -1.640036  0.397833  \n",
       "3580 -0.378025 -1.489587  \n",
       "5991 -0.622362  1.427335  \n",
       "...        ...       ...  \n",
       "572   1.533552  0.569417  \n",
       "3408 -0.988416 -0.116918  \n",
       "1825  0.554517  0.226250  \n",
       "641  -1.198295  0.569417  \n",
       "1723 -0.970165  0.226250  \n",
       "\n",
       "[2119 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "All models will be trained with oversampled data using SMOTE. Original set resulted in very poor recall rate in all models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp_smote_lr=Pipeline([\n",
    "    ('sampling',SMOTE(random_state=42)),\n",
    "    ('lr', LogisticRegression(solver='liblinear',max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('sampling', SMOTE(random_state=42)),\n",
       "  ('lr', LogisticRegression(max_iter=1000, solver='liblinear'))],\n",
       " 'verbose': False,\n",
       " 'sampling': SMOTE(random_state=42),\n",
       " 'lr': LogisticRegression(max_iter=1000, solver='liblinear'),\n",
       " 'sampling__k_neighbors': 5,\n",
       " 'sampling__n_jobs': None,\n",
       " 'sampling__random_state': 42,\n",
       " 'sampling__sampling_strategy': 'auto',\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 1000,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': None,\n",
       " 'lr__solver': 'liblinear',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_smote_lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_lr_params={\n",
    "    'sampling__k_neighbors':[5,6,7],\n",
    "    'sampling__sampling_strategy':['minority', 'not minority','auto'],\n",
    "    'lr__C':[0.2,0.4,0.6],\n",
    "    'lr__penalty':['l1','l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_lr=GridSearchCV(pp_smote_lr,pp_smote_lr_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.2, 0.4, 0.6], 'lr__penalty': ['l1', 'l2'],\n",
       "                         'sampling__k_neighbors': [5, 6, 7],\n",
       "                         'sampling__sampling_strategy': ['minority',\n",
       "                                                         'not minority',\n",
       "                                                         'auto']},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_lr.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156055465829867"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_lr.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256595353720961"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_lr.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling', SMOTE(k_neighbors=7, random_state=42)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.6, max_iter=1000, penalty='l1',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr=gs_smote_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr=model_lr.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdd5b0c13d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAddElEQVR4nO3df7xVVZ3/8debH4KACMiPQX4IKmGIYymRWpmmBlZfsUZnME0q52sZk2blr/o29q1h8vsonXIKi9TUMSU0G60UNNSxGhQRUwRluInCFQQBf/FD4N77+f6x98Xj5f44+3AP59y7308f+3H2XnufvdaBBx/X2mvttRQRmJnlTZdKF8DMrBIc/Mwslxz8zCyXHPzMLJcc/Mwsl7pVugCFBg7oGqNGdK90MSyDpesGVboIlsHO1zdRt22L9uQek07sHRs31Rd17RNPb58XEZP3JL9yqargN2pEdxbOG1HpYlgGR1zzpUoXwTJ4/pZr9vgeGzfVs3DeyKKu7Tp0xcA9zrBMqir4mVn1C6CBhkoXY4/5mZ+ZZRIEO6O+qK0tkm6UtF7SM82c+7qkkDSwIO0KSTWSlkuaVJB+tKQl6blrJbXZtHfwM7PMGor8rwg3Abs9E5Q0AjgFWFWQNg6YChyefmempK7p6euA84Ex6dbmc0YHPzPLJAjqo7itzXtFPAJsaubUvwGXkrSyG00BZkfE9ohYCdQAEyUNBfpGxIJI3te9BTi9rbz9zM/MMmug6DkBBkpaVHA8KyJmtfYFSacBL0XEU01ar8OARwuOa9O0nel+0/RWOfiZWSYB1Bcf/DZExIRiL5bUC/gm8NHmTrdQnJbSW+XgZ2aZZaj5ZXUIMBporPUNBxZLmkhSoyscCzccWJOmD28mvVV+5mdmmQSwM6KoLfO9I5ZExOCIGBURo0gC21ER8TJwDzBVUg9Jo0k6NhZGxFrgTUnHpL285wJ3t5WXg5+ZZRIE9UVubZF0O7AAGCupVtJ5LeYbsRSYAywD5gLTI3aNp7kAuJ6kE+SvwH1t5e1mr5llE1DfTq3eiDirjfOjmhzPAGY0c90iYHyWvB38zCyT5A2Pjs/Bz8wyEvXNdrB2LA5+ZpZJ0uHh4GdmOZOM83PwM7McanDNz8zyxjU/M8ulQNR3giHCDn5mlpmbvWaWO4HYEV3bvrDKOfiZWSbJIGc3e80sh9zhYWa5EyHqwzU/M8uhBtf8zCxvkg6Pjh86Ov4vMLO9yh0eZpZb9R7nZ2Z54zc8zCy3Gtzba2Z5k0xs4OBnZjkTiJ1+vc3M8iaCTjHIueP/AjPby0RDkVubd5JulLRe0jMFad+X9JykpyX9RlK/gnNXSKqRtFzSpIL0oyUtSc9dm67f2yoHPzPLJEhqfsVsRbgJmNwk7QFgfET8LfA/wBUAksYBU4HD0+/MlNTY/r4OOJ9kIfMxzdxzNw5+ZpZZPV2K2toSEY8Am5qk3R8Rdenho8DwdH8KMDsitkfESpIFyidKGgr0jYgFERHALcDpbeXtZ35mlkmgvTmZ6eeBX6X7w0iCYaPaNG1nut80vVUOfmaWSbJ0ZdGhY6CkRQXHsyJiVjFflPRNoA74ZWNSC8VpKb1VDn5mllGmRcs3RMSEzDlI04BPACelTVlIanQjCi4bDqxJ04c3k94qP/Mzs0yC5A2PYrZSSJoMXAacFhFbC07dA0yV1EPSaJKOjYURsRZ4U9IxaS/vucDdbeXjmp+ZZdZeMzlLuh04gaR5XAtcSdK72wN4IB2x8mhEfDEilkqaAywjaQ5Pj4j69FYXkPQc7wvcl26tcvAzs0wi1G7v9kbEWc0k39DK9TOAGc2kLwLGZ8nbwc/MMkk6PPx6m5nljtfwMLMcSjo8PJmpmeWQp7Qys9zZy294lI2Dn5ll5gWMzCx3ImBng4OfmeVM0ux18DOzHGqvNzwqycGvBFdfPILH/tCXfgPrmPXQ8necu+O6QVz/3WHMWbKE/Q+o57kne/GjS5J3sQP4zNde5gOnvg7AJX93KJvWdWOfnsl729+b/Vf6DazDym/uebeydWd36htEfUMXpt52Bt//+P2M6v8aAPv12MGb2/fhzFv/HoDz3reYTx3xLPUN4qqHPsh/vziygqWvLA91KUL6gvKPgK7A9RFxVTnz21s++g+bOO1zG/j+Re/8B7D+pe48+ch+DB62Y1faqLHb+PHc5XTtBhvXdeOCk8dyzCmv0zX9k7/sJy/yriO37c3iW+rzc07jtbf23XV8ye8/umv/68f/N5t37APAwQM2cephNZx+81QG997Cz8/4LZ/4xVmdoulXms7R7C3bL0inl/4JcCowDjgrnYa6wzvimC3s179+t/SffXsY5/2fNRSuHtCzV+wKdDu3d6HtlQWs8oJJY2u497lDATjxkBe477lD2VnflZfe6Muq1/bniL9ZX+EyVlZ7reFRSeWs+U0EaiLieQBJs0mmoV5WxjwrZsG8vgz8m50ccvhbu517bnEvrv7qCNbX7sOl/75qVzAEuPrikXTpAh/8+Gt8+ivrHBz3kgB+9ne/A+COpw/nziVv/3/56GFr2bilF6te6wfAkP228PTaIbvOr9vcm8F9tuzN4laVpLfX7/a2ZhiwuuC4Fnh/04sknU+y8Agjh3XMR5BvbRW3XzuE793+12bPH3bUVn7+8HJWrejB9y8ayftOfIN9egaX/fhFBg7dydbNXfjuP47iD3f255QzX93Lpc+nc2d/kle29GbAvluZdcbvWLmpH0+8dCAApx62gnuXH7rrWjUzKXCb0wR3Yp1lkHM5G+5FTS0dEbMiYkJETBh0QMf8v8naF3vw8qp9uODkwzh34jheWdud6ZPGsmn9O4P5yDHb6dmrgReW9wRg4NCdAPTq08CJn3yN5U/22utlz6tXtvQGYNO2XsyvGc34tBnbVQ2cfOhK5hUEv5ff7MOQPpt3HQ/ps4VXNvfeuwWuMp2h2VvO4NfSlNOdzuh3v8WcJUu5ZeEyblm4jEFDd/KTecsZMLiOl1ftQ33agbuutju1f+3JkOE7qK+D1zcmwb5uJzz2h76MOmz3JrO1v3277aRX9x279o87aDU1GwcAcMxBtax8tR/rNvfZdf3Dz4/i1MNq6N61nmF93+Cgfq+x5OXBFSl7NWjs7S1mq2blbGc+DoxJp5t+iWS9zU+XMb+95nsXHMTTC/rw+qZunH30OD7ztZeZ/OlNzV77zMLe/OrHo+nWDbp0Cb78r7Xsf0A9b23twjc+fQj1daK+Ho760GZOPXvjXv4l+XRA72388LS5QFLTu/e5Mfz5haTn/tSxNdz73Jh3XP/XjQOYt/wQ7p42m7oGMePBD3WK3s490Rl+v95eG6QMN5c+BvyQZKjLjeksrC2acGTPWDhvRGuXWJU54povVboIlsHzt1zDtpdX71GVrP9hg+MjN55R1LV3feC6J0pZwGhvKGsPQ0TcC9xbzjzMbO+r9iZtMTpm96qZVYzf8DCz3HLwM7Pc8Tg/M8ut9hrnJ+lGSeslPVOQNkDSA5JWpJ/9C85dIalG0nJJkwrSj5a0JD13bbp4easc/Mwskwioa+hS1FaEm4DJTdIuB+ZHxBhgfnpMOjfAVODw9Dsz0zkEAK4jeVNsTLo1veduHPzMLLP2GuQcEY8ATQfJTgFuTvdvBk4vSJ8dEdsjYiVQA0yUNBToGxELIhm7d0vBd1rkZ35mlknGZ34DJS0qOJ4VEbPa+M6QiFgLEBFrJTW+TjMMeLTguto0bWe63zS9VQ5+ZpZZFB/8NrTjIOeW5gsoah6BptzsNbPMyjyxwbq0KUv62Th5YkvzBdSm+03TW+XgZ2aZRJR9YoN7gGnp/jTg7oL0qZJ6pHMGjAEWpk3kNyUdk/bynlvwnRa52WtmGSXrnrTLnaTbgRNIng3WAlcCVwFzJJ0HrALOBIiIpZLmkEyIXAdMj4jGKdUvIOk53he4L91a5eBnZplleObXxn3irBZOndTC9TOA3SZIiYhFwPgseTv4mVkmfrfXzPIpkud+HZ2Dn5llVu1T1BfDwc/MMol27PCoJAc/M8vMzV4zy6X26u2tJAc/M8skwsHPzHLKQ13MLJf8zM/McicQDe7tNbM86gQVPwc/M8vIHR5mlludoOrn4GdmmXXqmp+kf6eV+B4RF5alRGZW1QJoaOjEwQ9Y1Mo5M8urADpzzS8ibi48ltQ7IraUv0hmVu06wzi/NgfrSDpW0jLg2fT4SEkzy14yM6teUeRWxYoZqfhDYBKwESAingKOL2OZzKyqiYjitmpWVG9vRKxOFkXapb6la80sB6q8VleMYoLfaknHASFpH+BC0iawmeVQQHSC3t5imr1fBKYDw4CXgPekx2aWWypyq15tBr+I2BARZ0fEkIgYFBHnRMTGvVE4M6tS7dThIeliSUslPSPpdkk9JQ2Q9ICkFeln/4Lrr5BUI2m5pEl78hOK6e09WNJvJb0iab2kuyUdvCeZmlkH1w7BT9IwksdoEyJiPNAVmApcDsyPiDHA/PQYSePS84cDk4GZkrqW+hOKafbeBswBhgIHAncAt5eaoZl1cI2DnIvZ2tYN2FdSN6AXsAaYAjSOM74ZOD3dnwLMjojtEbESqAEmlvozigl+ioj/iIi6dLuVTtHXY2aliihuAwZKWlSwnf/2PeIl4AfAKmAt8HpE3A8MiYi16TVrgcHpV4YBqwuKUZumlaS1d3sHpLsPSbocmE0S9P4B+H2pGZpZJ1B8b++GiJjQ3In0Wd4UYDTwGnCHpHNauVdzmZZcEWttqMsT6Y0bM/xCkwy/W2qmZtaxqX3aficDKyPiFQBJdwHHAeskDY2ItZKGAuvT62uBEQXfH07STC5Ja+/2ji71pmbWibXfq2urgGMk9QK2ASeRTKiyBZgGXJV+3p1efw9wm6RrSPofxgALS828qDc8JI0HxgE9G9Mi4pZSMzWzjqzozoxWRcRjku4EFgN1wJPALKAPMEfSeSQB8sz0+qWS5gDL0uunR0TJb5u1GfwkXQmcQBL87gVOBf4EOPiZ5VU7dXlGxJXAlU2St5PUApu7fgYwoz3yLqa394y0IC9HxOeAI4Ee7ZG5mXVQDUVuVayYZu+2iGiQVCepL8nDRw9yNsurzj6ZaYFFkvoBPyfpAd7MHjxkNLOOr516eyuqzeAXEV9Kd38qaS7QNyKeLm+xzKyqdebgJ+mo1s5FxOLyFMnMrPxaq/ld3cq5AD7SzmXhf57uxaQD39Pet7UyGtHfUzt2JLWvv9Uu9+nUzd6IOHFvFsTMOoggy+ttVcuLlptZdp255mdm1pJO3ew1M2tRJwh+xczkLEnnSPrn9HikpJInEDSzTiAn6/bOBI4FzkqP3wR+UrYSmVlVUxS/VbNimr3vj4ijJD0JEBGvpktYmlle5aS3d2e6SEgASBpE1b+ybGblVO21umIU0+y9FvgNMFjSDJLprP61rKUys+rWCZ75FfNu7y8lPUEyrZWA0yPCw/rN8qoDPM8rRjGTmY4EtgK/LUyLiFXlLJiZVbE8BD+SldoaFzLqSbLS0nKShYPNLIfUCZ76F9PsPaLwOJ3t5QstXG5m1iFkfsMjIhZLel85CmNmHUQemr2Svlpw2AU4CnilbCUys+qWlw4PYL+C/TqSZ4C/Lk9xzKxD6OzBLx3c3CciLtlL5TGzjqCdgl+6PtD1wPj0rp8n6VD9FTAKeAH4+4h4Nb3+CuA8oB64MCLmlZp3i4OcJXVLFwRucTp7M8sfkfT2FrMV4UfA3Ig4jGRZ3GeBy4H5ETEGmJ8eI2kcMJVkpMlkYGZaQStJazW/hSSB7y+S7gHuALY0noyIu0rN1Mw6sHZ65pcuhXs88FmAiNgB7JA0BTghvexm4GHgMmAKMDsitgMrJdUAE4EFpeRfzDO/AcBGkjU7Gsf7BeDgZ5ZXxQe/gZIWFRzPiohZ6f7BJJ2nv5B0JMnSuBcBQyJiLUBErJU0OL1+GPBowb1q07SStBb8Bqc9vc/wdtBr1Aked5pZyYqPABsiYkIL57qRtC6/HBGPSfoRaRO3Bc1NJVNyLGptYoOuQJ90269gv3Ezs5xqp/n8aoHaiHgsPb6TJBiukzQUIP1cX3D9iILvDwfWlPobWqv5rY2I75R6YzPrxNqh7RcRL0taLWlsRCwnmTxlWbpNA65KP+9Ov3IPcJuka4ADgTEkfRMlaS34dfzZCs2s/UW7vtv7ZeCX6QTJzwOfI2mRzpF0HrAKOBMgIpZKmkMSHOuA6emIlJK0FvxOKvWmZtbJtdNT/4j4C9DcM8Fm409EzABmtEferS1avqk9MjCzzicvr7eZmb2Tg5+Z5U4HmKK+GA5+ZpaJcLPXzHLKwc/M8snBz8xyycHPzHInRzM5m5m9k4OfmeVRLpauNDNrys1eM8sfD3I2s9xy8DOzvPEbHmaWW2ro+NHPwc/MsvEzPzPLKzd7zSyfHPzMLI9c8zOzfHLwM7Pcad/V2yrGwc/MMuks4/y6VLoAZtYBRRS3FUFSV0lPSvpdejxA0gOSVqSf/QuuvUJSjaTlkibtyU9w8DOzzBTFbUW6CHi24PhyYH5EjAHmp8dIGgdMBQ4HJgMzJXUt9Te42duOBh24g0t+tIr+g+uIBrj31gP4zxsGce4lazl20htEwGsbuvGDr4xk07rulS6upaacU8ukM9Ygwdw7h3L3f4zggx9dz9nTX2DEwVu5eOpRrFjat9LFrB7tOMhZ0nDg4yQLkX81TZ4CnJDu3ww8DFyWps+OiO3ASkk1wERgQSl5l63mJ+lGSeslPVOuPKpNfZ2Y9Z0D+d8fPoyLPjGG//XZDYwc8xZ3XjeYC04ey5dOGctjf+jLORevq3RRLXXQoZuZdMYaLp56NNM/NYGJH97IgSO38mJNb/7lovE8s2j/ShexKqmhuA0YKGlRwXZ+k1v9ELgUKOxCGRIRawHSz8Fp+jBgdcF1tWlaScrZ7L2JpGqaG5vWd6dmSS8Atm3pyuqangwcupOtm9+umffct6HYRyG2F4w4eCvLn+rL9re60lDfhWcW9eO4kzew+vnevPRCr0oXr2plCH4bImJCwTZr1z2kTwDrI+KJYrNtJq3kf01la/ZGxCOSRpXr/tVuyPAdHDJ+G88tTv4BffaytZx85qtseaMrl55xSIVLZ41erOnNtItWst/+O9mxvQsTPrSJFUv3q3SxqltQdGdGGz4AnCbpY0BPoK+kW4F1koZGxFpJQ4H16fW1wIiC7w8H1pSaecU7PCSd31gl3sn2ShenXfTsVc+3rn+Bn/7zgbtqfTf9v6GcM2EcD97Vj9M+v6HCJbRGq5/vzR03jGTG9U/x3Z89zcrlvamvb66CYYXao8MjIq6IiOERMYqkI+PBiDgHuAeYll42Dbg73b8HmCqph6TRwBhgYam/oeLBLyJmNVaJu9Oj0sXZY127Bd+6/gUevKs/f76v327nH/pNfz74sdf3fsGsRfffNZQLz5zApdPey5uvd2fNi/tWukjVL4rcSnMVcIqkFcAp6TERsRSYAywD5gLTI6K+1EwqHvw6l+CrV69m9Yqe3DVr0K7UA0e/XaM9ZtLrrK7p+EG+M9l/wA4ABg19i+NOfoX/undwG9/It8ZBzu041IWIeDgiPpHub4yIkyJiTPq5qeC6GRFxSESMjYj79uR3eKhLOzp84hZOPvNVnl/Wk5kPLAfgF98byuSzNjH8kO00NMD6l/bh2suGV7ikVuibP1xK3347qasTM//lXWx+ozvHnvQKF3xjBfsP2Mm3Zy7h+eV9+Nb5R1a6qNUhwpOZtkbS7SRjdQZKqgWujIgbypVfNVi6sA+TDtz9H8jjD3qMWDW79Nz37pa2YP4gFswf1MzVBnhig9ZExFnlureZVVZneLfXzV4zyyYAN3vNLJc6fuxz8DOz7NzsNbNccm+vmeWPl640szxKBjl3/Ojn4Gdm2XkNDzPLI9f8zCx//MzPzPLJ7/aaWV652WtmueNFy80st1zzM7Nc6vixz8HPzLJTQ8dv9zr4mVk2gQc5m1n+iPAgZzPLqU4Q/Lx6m5llF1Hc1gpJIyQ9JOlZSUslXZSmD5D0gKQV6Wf/gu9cIalG0nJJk/bkJzj4mVk2jc/8itlaVwd8LSLeDRwDTJc0DrgcmB8RY4D56THpuanA4cBkYKakrqX+DAc/M8tMDQ1Fba2JiLURsTjdfxN4FhgGTAFuTi+7GTg93Z8CzI6I7RGxEqgBJpb6Gxz8zCyjIpu8GZ4LShoFvBd4DBgSEWshCZBA4yryw4DVBV+rTdNK4g4PM8smyBLYBkpaVHA8KyJmFV4gqQ/wa+ArEfGGpJbu1dyJknteHPzMLLvix/ltiIgJLZ2U1J0k8P0yIu5Kk9dJGhoRayUNBdan6bXAiIKvDwfWZCp3ATd7zSwzRRS1tXqPpIp3A/BsRFxTcOoeYFq6Pw24uyB9qqQekkYDY4CFpf4G1/zMLLv2Gef3AeAzwBJJf0nTvgFcBcyRdB6wCjgzyTKWSpoDLCPpKZ4eEfWlZu7gZ2bZRED9nr/fFhF/ovnneAAntfCdGcCMPc4cBz8zK0UneMPDwc/MsnPwM7PcCcBreJhZ/gREx5/TysHPzLIJ2qXDo9Ic/MwsOz/zM7NccvAzs/zJNmlBtXLwM7NsAvACRmaWS675mVn+tM/rbZXm4Gdm2QSEx/mZWS75DQ8zyyU/8zOz3Ilwb6+Z5ZRrfmaWP0HUlzyBctVw8DOzbDyllZnlloe6mFneBBCu+ZlZ7oQnMzWznOoMHR6KKuqylvQK8GKly1EGA4ENlS6EZdJZ/84OiohBe3IDSXNJ/nyKsSEiJu9JfuVSVcGvs5K0KCImVLocVjz/nXV+XSpdADOzSnDwM7NccvDbO2ZVugCWmf/OOjk/8zOzXHLNz8xyycHPzHLJwa+MJE2WtFxSjaTLK10ea5ukGyWtl/RMpcti5eXgVyaSugI/AU4FxgFnSRpX2VJZEW4CqnJQrrUvB7/ymQjURMTzEbEDmA1MqXCZrA0R8QiwqdLlsPJz8CufYcDqguPaNM3MqoCDX/momTSPKzKrEg5+5VMLjCg4Hg6sqVBZzKwJB7/yeRwYI2m0pH2AqcA9FS6TmaUc/MokIuqAfwLmAc8CcyJiaWVLZW2RdDuwABgrqVbSeZUuk5WHX28zs1xyzc/McsnBz8xyycHPzHLJwc/McsnBz8xyycGvA5FUL+kvkp6RdIekXntwr5sknZHuX9/apAuSTpB0XAl5vCBpt1W+Wkpvcs3mjHl9W9LXs5bR8svBr2PZFhHviYjxwA7gi4Un05lkMouIf4yIZa1ccgKQOfiZVTMHv47rj8Chaa3sIUm3AUskdZX0fUmPS3pa0hcAlPixpGWSfg8MbryRpIclTUj3J0taLOkpSfMljSIJshentc4PSRok6ddpHo9L+kD63QMk3S/pSUk/o/n3m99B0n9KekLSUknnNzl3dVqW+ZIGpWmHSJqbfuePkg5rlz9Ny51ulS6AZSepG8k8gXPTpInA+IhYmQaQ1yPifZJ6AH+WdD/wXmAscAQwBFgG3NjkvoOAnwPHp/caEBGbJP0U2BwRP0ivuw34t4j4k6SRJG+xvBu4EvhTRHxH0seBdwSzFnw+zWNf4HFJv46IjUBvYHFEfE3SP6f3/ieShYW+GBErJL0fmAl8pIQ/Rss5B7+OZV9Jf0n3/wjcQNIcXRgRK9P0jwJ/2/g8D9gfGAMcD9weEfXAGkkPNnP/Y4BHGu8VES3Na3cyME7aVbHrK2m/NI9Ppd/9vaRXi/hNF0r6ZLo/Ii3rRqAB+FWafitwl6Q+6e+9oyDvHkXkYbYbB7+OZVtEvKcwIQ0CWwqTgC9HxLwm132MtqfUUhHXQPK45NiI2NZMWYp+X1LSCSSB9NiI2CrpYaBnC5dHmu9rTf8MzErhZ36dzzzgAkndASS9S1Jv4BFgavpMcChwYjPfXQB8WNLo9LsD0vQ3gf0KrrufpAlKet170t1HgLPTtFOB/m2UdX/g1TTwHUZS82zUBWisvX6apDn9BrBS0plpHpJ0ZBt5mDXLwa/zuZ7ked7idBGen5HU8H8DrACWANcB/9X0ixHxCslzurskPcXbzc7fAp9s7PAALgQmpB0qy3i71/n/AsdLWkzS/F7VRlnnAt0kPQ18F3i04NwW4HBJT5A80/tOmn42cF5avqV4aQArkWd1MbNccs3PzHLJwc/McsnBz8xyycHPzHLJwc/McsnBz8xyycHPzHLp/wP8D7r+ypBImAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_lr,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464592023405071"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_lr.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569781686135538"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['LR']={'train_acc':gs_smote_lr.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_lr.best_score_,\n",
    "              'test_acc':gs_smote_lr.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_lr.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_lr),\n",
    "              'train_recall':recall_score(y_train,model_lr.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_lr)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: K Nearest Neighbors with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp_smote_knn=Pipeline([\n",
    "    ('sampling',SMOTE(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('sampling', SMOTE(random_state=42)),\n",
       "  ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'sampling': SMOTE(random_state=42),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'sampling__k_neighbors': 5,\n",
       " 'sampling__n_jobs': None,\n",
       " 'sampling__random_state': 42,\n",
       " 'sampling__sampling_strategy': 'auto',\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_smote_knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_knn_params={\n",
    "    'sampling__k_neighbors':[5,6,7],\n",
    "    'sampling__sampling_strategy':['minority', 'not minority','auto'],\n",
    "    'knn__n_neighbors':[5,6,7],\n",
    "    'knn__weights':['uniform','distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_knn=GridSearchCV(pp_smote_knn,pp_smote_knn_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__n_neighbors': [5, 6, 7],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'sampling__k_neighbors': [5, 6, 7],\n",
       "                         'sampling__sampling_strategy': ['minority',\n",
       "                                                         'not minority',\n",
       "                                                         'auto']},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_knn.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9753212063851936"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_knn.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752439077744235"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_knn.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling',\n",
       "                 SMOTE(k_neighbors=6, random_state=42,\n",
       "                       sampling_strategy='minority')),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=7))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn=gs_smote_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn=model_knn.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdd3e92b280>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_knn,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165617352878288"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_knn.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697615610097563"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['KNN']={'train_acc':gs_smote_knn.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_knn.best_score_,\n",
    "              'test_acc':gs_smote_knn.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_knn.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_knn),\n",
    "              'train_recall':recall_score(y_train,model_knn.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_knn)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Random Forest Classifier with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_rf=Pipeline([\n",
    "    ('sampling',SMOTE(random_state=42)),\n",
    "    ('rf',RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_rf_params={\n",
    "    'sampling__k_neighbors':[5,6,7,8],\n",
    "    'sampling__sampling_strategy':['minority', 'not minority', 'auto'],\n",
    "    'rf__max_depth':[4,5,6],\n",
    "    'rf__n_estimators':[100,200,300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_rf=GridSearchCV(pp_smote_rf,pp_smote_rf_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': [4, 5, 6],\n",
       "                         'rf__n_estimators': [100, 200, 300],\n",
       "                         'sampling__k_neighbors': [5, 6, 7, 8],\n",
       "                         'sampling__sampling_strategy': ['minority',\n",
       "                                                         'not minority',\n",
       "                                                         'auto']},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_rf.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9012533097627639"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_rf.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542612766329789"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_rf.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling',\n",
       "                 SMOTE(random_state=42, sampling_strategy='not minority')),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=6, n_estimators=300,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf=gs_smote_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf=model_rf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdd3ea03460>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_rf,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165617352878288"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_knn.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697615610097563"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['RF']={'train_acc':gs_smote_rf.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_rf.best_score_,\n",
    "              'test_acc':gs_smote_rf.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_rf.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_rf),\n",
    "              'train_recall':recall_score(y_train,model_rf.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_rf)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Extra Trees Classifiers with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_et=Pipeline([\n",
    "    ('sampling',SMOTE(random_state=42)),\n",
    "    ('et',ExtraTreesClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_et_params={\n",
    "    'sampling__k_neighbors':[5,6,7,8],\n",
    "    'sampling__sampling_strategy':['minority', 'not minority', 'auto'],\n",
    "    'et__max_depth':[6,7,8],\n",
    "    'et__n_estimators':[300,400,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_et=GridSearchCV(pp_smote_et,pp_smote_et_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                                       ('et',\n",
       "                                        ExtraTreesClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'et__max_depth': [6, 7, 8],\n",
       "                         'et__n_estimators': [300, 400, 500],\n",
       "                         'sampling__k_neighbors': [5, 6, 7, 8],\n",
       "                         'sampling__sampling_strategy': ['minority',\n",
       "                                                         'not minority',\n",
       "                                                         'auto']},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_et.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096151729561653"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_et.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848064050400315"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_et.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling',\n",
       "                 SMOTE(random_state=42, sampling_strategy='not minority')),\n",
       "                ('et',\n",
       "                 ExtraTreesClassifier(max_depth=8, n_estimators=300,\n",
       "                                      random_state=42))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_et.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_et=gs_smote_et.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_et=model_et.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdc7e698550>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_et,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087463556851312"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_et.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087719298245614"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['ET']={'train_acc':gs_smote_et.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_et.best_score_,\n",
    "              'test_acc':gs_smote_et.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_et.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_et),\n",
    "              'train_recall':recall_score(y_train,model_et.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_et)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Support Vector Machines with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_svc=Pipeline([\n",
    "    ('sampling',SMOTE()),\n",
    "    ('svc',SVC(probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_svc_params={\n",
    "# params was executed but poly kernel has better results hence these features was comment out to ensure notebook run faster\n",
    "#     {'sampling__k_neighbors':[5,6,7],\n",
    "#      'sampling__sampling_strategy':['minority', 'not minority', 'auto'],\n",
    "#      'svc__C':[0.2,0.4],\n",
    "#      'svc__kernel':['rbf', 'sigmoid']},\n",
    "#     {'sampling__k_neighbors':[5,6,7], \n",
    "    'sampling__sampling_strategy':['minority', 'not minority', 'auto'],\n",
    "    'svc__C':[0.2,0.4],\n",
    "    'svc__kernel':['poly'],\n",
    "    'svc__degree':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_svc=GridSearchCV(pp_smote_svc,pp_smote_svc_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                       ('svc', SVC(probability=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'sampling__sampling_strategy': ['minority',\n",
       "                                                         'not minority',\n",
       "                                                         'auto'],\n",
       "                         'svc__C': [0.2, 0.4], 'svc__degree': [2, 3],\n",
       "                         'svc__kernel': ['poly']},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_svc.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879516150381656"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_svc.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574922343264646"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_svc.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling', SMOTE()),\n",
       "                ('svc', SVC(C=0.2, kernel='poly', probability=True))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc=gs_smote_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svc=model_svc.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdc7e5f83a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_svc,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8075292648241734"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_svc.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920374502340639"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['SVC']={'train_acc':gs_smote_svc.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_svc.best_score_,\n",
    "              'test_acc':gs_smote_svc.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_svc.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_svc),\n",
    "              'train_recall':recall_score(y_train,model_svc.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_svc)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp_smote_xgb=Pipeline([\n",
    "    ('sampling',SMOTE(random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_smote_xgb_params={\n",
    "    'sampling__k_neighbors': [5],\n",
    "    'xgb__lambda': [0.2],\n",
    "    'xgb__alpha': [0.1],\n",
    "    'xgb__colsample_bytree': [0.9],\n",
    "    'xgb__subsample': [0.8],\n",
    "    'xgb__gamma': [0.4],\n",
    "    'xgb__gpu_hist': ['gpu_hist'],\n",
    "    'xgb__learning_rate': [0.1],\n",
    "    'xgb__max_depth': [5],\n",
    "    'xgb__min_child_weight': [2],\n",
    "    'xgb__n_estimators': [100],\n",
    "    'xgb__n_jobs': [-1],\n",
    "    'xgb__verbosity': [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote_xgb=GridSearchCV(pp_smote_xgb,pp_smote_xgb_params,cv=5,scoring='roc_auc',verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[09:50:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { gpu_hist } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 56 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 56 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 52 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 6 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 2 pruned nodes, max_depth=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 6 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 6 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 42 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:40] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[09:50:41] INFO: /Users/travis/build/dmlc/xgboost/src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      mi...\n",
       "             param_grid={'sampling__k_neighbors': [5], 'xgb__alpha': [0.1],\n",
       "                         'xgb__colsample_bytree': [0.9], 'xgb__gamma': [0.4],\n",
       "                         'xgb__gpu_hist': ['gpu_hist'], 'xgb__lambda': [0.2],\n",
       "                         'xgb__learning_rate': [0.1], 'xgb__max_depth': [5],\n",
       "                         'xgb__min_child_weight': [2],\n",
       "                         'xgb__n_estimators': [100], 'xgb__n_jobs': [-1],\n",
       "                         'xgb__subsample': [0.8], 'xgb__verbosity': [2]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_xgb.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140375638982399"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_xgb.score(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594150588441178"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_xgb.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sampling', SMOTE(random_state=42)),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(alpha=0.1, base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.9, gamma=0.4,\n",
       "                               gpu_hist='gpu_hist', gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', lambda=0.2,\n",
       "                               learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=2, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0.100000001, reg_lambda=0.200000003,\n",
       "                               scale_pos_weight=1, subsample=0.8,\n",
       "                               tree_method='exact', use_label_encoder=False,\n",
       "                               validate_parameters=1, verbosity=2))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampling__k_neighbors': 5,\n",
       " 'xgb__alpha': 0.1,\n",
       " 'xgb__colsample_bytree': 0.9,\n",
       " 'xgb__gamma': 0.4,\n",
       " 'xgb__gpu_hist': 'gpu_hist',\n",
       " 'xgb__lambda': 0.2,\n",
       " 'xgb__learning_rate': 0.1,\n",
       " 'xgb__max_depth': 5,\n",
       " 'xgb__min_child_weight': 2,\n",
       " 'xgb__n_estimators': 100,\n",
       " 'xgb__n_jobs': -1,\n",
       " 'xgb__subsample': 0.8,\n",
       " 'xgb__verbosity': 2}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_smote_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=gs_smote_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb=model_xgb.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdc7ecf9370>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model_xgb,X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972573030542668"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,model_xgb.predict(X_train_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552937830861443"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['XGB']={'train_acc':gs_smote_xgb.score(X_train_sc,y_train),\n",
    "              'val_acc':gs_smote_xgb.best_score_,\n",
    "              'test_acc':gs_smote_xgb.score(X_test_sc,y_test),\n",
    "              'train_auc':roc_auc_score(y_train,model_xgb.predict(X_train_sc)),\n",
    "              'test_auc':roc_auc_score(y_test,pred_xgb),\n",
    "              'train_recall':recall_score(y_train,model_xgb.predict(X_train_sc)),\n",
    "              'test_recall':recall_score(y_test,pred_xgb)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RF</th>\n",
       "      <th>ET</th>\n",
       "      <th>SVC</th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.815606</td>\n",
       "      <td>0.975321</td>\n",
       "      <td>0.901253</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.879516</td>\n",
       "      <td>0.914038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.786606</td>\n",
       "      <td>0.742261</td>\n",
       "      <td>0.823720</td>\n",
       "      <td>0.820316</td>\n",
       "      <td>0.820955</td>\n",
       "      <td>0.822325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_acc</th>\n",
       "      <td>0.825660</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.854261</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.857492</td>\n",
       "      <td>0.859415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.746459</td>\n",
       "      <td>0.916562</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.508746</td>\n",
       "      <td>0.807529</td>\n",
       "      <td>0.797257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc</th>\n",
       "      <td>0.756978</td>\n",
       "      <td>0.697616</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.755294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.801749</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.842566</td>\n",
       "      <td>0.696793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.622807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LR       KNN        RF        ET       SVC       XGB\n",
       "train_acc     0.815606  0.975321  0.901253  0.909615  0.879516  0.914038\n",
       "val_acc       0.786606  0.742261  0.823720  0.820316  0.820955  0.822325\n",
       "test_acc      0.825660  0.775244  0.854261  0.848064  0.857492  0.859415\n",
       "train_auc     0.746459  0.916562  0.500000  0.508746  0.807529  0.797257\n",
       "test_auc      0.756978  0.697616  0.504386  0.508772  0.792037  0.755294\n",
       "train_recall  0.801749  0.959184  0.000000  0.017493  0.842566  0.696793\n",
       "test_recall   0.798246  0.543860  0.008772  0.017544  0.807018  0.622807"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection & Evaluation of Results \n",
    "\n",
    "The metrics used for comparison are: Accuracy, AUC and Recall. \n",
    "\n",
    "**Accuracy**\n",
    "<br>The results of the hyperparameter tuning above show that all models had relatively high training and cross-validated scores, indicating that some of the models may have overfit on the training data. However, after comparison with the test accuracy, we note that all models except KNN have test accuracies close to the training accuracies, which suggests that the models generalise well to new data. \n",
    "\n",
    "**AUC-ROC** \n",
    "<br> Due to the imbalanced classes in our dataset, the AUC-ROC curve allows us to assess how well our model performs at distinguishing between the positive and negative classes. We observe that the tree-based models (RF and ET) have the lowest scores of about 0.5, meaning that both models have no class separation capacity whatsoever.\n",
    "\n",
    "The disparity between KNN's training and test AUC shows significantly higher degree of overfitting compared to the remaining 3 models. Of the 3, SVC has the highest score and also generalises well to new data. \n",
    "\n",
    "\n",
    "**Recall** \n",
    "<br> The final metric we use is recall (i.e sensitivity / true positivity rate). Given the severe imbalanced of WNV-positive (i.e WNV=1) classes, recall is an important metric for us to determine how well the model classifies whether the WNV is present in a given location, i.e we want to ensure that pesticides are sprayed in locations which have the WNV. From our results, SVC and LR have the best recall scores while the tree models are the worst-performing. \n",
    "\n",
    "Overall, **SVC** has the best performance in terms of the 3 metrics we're using. However, there is a drawback that SVC fitted using polynomial kernel does not provide any coefficient to weigh the feature columns. Hence we examine the next best estimator, which is logistic regression, for its cofficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract coefficients and feature names\n",
    "log_coefs = model_lr.named_steps.lr.coef_\n",
    "log_features = X_train_sc.columns.to_list()\n",
    "\n",
    "log_coefs_df = pd.Series(log_coefs[0], index = log_features)\n",
    "# filter top positive coefficients \n",
    "pos_coefs = log_coefs_df[log_coefs_df > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "pos_coefs.sort_values().plot(kind = \"barh\")\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);\n",
    "plt.title(\"Top Coefficients from Logistic Regression\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain On Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the final selected model, we fit with preceding years to predict the data for each subsequent year. \n",
    "For example, model is fitted with 2007 train data to perform prediction on 20008 test data. 2007 and 2009 train data is used to predict 2010 test data and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('../datasets/test_weather.csv',index_col='id',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_08=test[test['date'].dt.year==2008][X_train_sc.columns]\n",
    "test_10=test[test['date'].dt.year==2010][X_train_sc.columns]\n",
    "test_12=test[test['date'].dt.year==2012][X_train_sc.columns]\n",
    "test_14=test[test['date'].dt.year==2014][X_train_sc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_07=df_train[df_train['date'].dt.year==2007][X_train_sc.columns]\n",
    "train_09=df_train[df_train['date'].dt.year<=2009][X_train_sc.columns]\n",
    "train_11=df_train[df_train['date'].dt.year<=2011][X_train_sc.columns]\n",
    "train_13=df_train[df_train['date'].dt.year<=2013][X_train_sc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_07=df_train[df_train['date'].dt.year==2007]['wnv']\n",
    "y_09=df_train[df_train['date'].dt.year<=2009]['wnv']\n",
    "y_11=df_train[df_train['date'].dt.year<=2011]['wnv']\n",
    "y_13=df_train[df_train['date'].dt.year<=2013]['wnv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1=StandardScaler()\n",
    "train_07_sc=ss1.fit_transform(train_07)\n",
    "test_08_sc=ss1.transform(test_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2=StandardScaler()\n",
    "train_09_sc=ss2.fit_transform(train_09)\n",
    "test_10_sc=ss1.transform(test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss3=StandardScaler()\n",
    "train_11_sc=ss3.fit_transform(train_11)\n",
    "test_12_sc=ss1.transform(test_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss4=StandardScaler()\n",
    "train_13_sc=ss3.fit_transform(train_13)\n",
    "test_14_sc=ss1.transform(test_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc.fit(train_07_sc,y_07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred08=pd.DataFrame(model_svc.predict_proba(test_08_sc)[:,1],index=test_08.index,columns=['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc.fit(train_09_sc,y_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred10=pd.DataFrame(model_svc.predict_proba(test_10_sc)[:,1],index=test_10.index,columns=['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc.fit(train_11_sc,y_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred12=pd.DataFrame(model_svc.predict_proba(test_12_sc)[:,1],index=test_12.index,columns=['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc.fit(train_13_sc,y_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred14=pd.DataFrame(model_svc.predict_proba(test_14_sc)[:,1],index=test_14.index,columns=['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle=pd.concat([pred08,pred10,pred12,pred14],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.to_csv('../datasets/kaggle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-Benefit Analysis \n",
    "\n",
    "As part of our cost-benefit analysis, we studied research papers which highlighted that an estimated \\\\$778 million was incurred in both short-term and long-term, direct and indirect medical costs associated with the WNV disease, over a 15-year period from 1999 to 2014 across the US. \n",
    "\n",
    "<a href=\"https://wwwnc.cdc.gov/eid/article/16/3/09-0667_article\">Louisiana state data</a> showed that total epidemic costs were around \\\\$20 million for 329 cases, which averages to about \\\\$61,000 per infected case. We also explored a 2005 California economic cost analysis of the virus where the total economic impact was $2.98 million for 163 cases. This averaged the economic impact to around \\\\$18,282 per case, whereas vector control cost was \\\\$701,790. Their analysis also revealed that only <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3322011/\">15 cases</a> of WNV would need to be prevented to justify the cost of the pesticide spraying. \n",
    "\n",
    "However, their analysis is not backed up by our EDA process. Spatial data showing the spray locations did not show any noticeable reductions in the WNV-positive mosquito hot spot, thus we would recommend alternative measures to use in conjunction with the spraying. \n",
    "\n",
    "To increase the cost-effectiveness of pesticide spraying, we advise against spraying when average wind speeds are high (i.e below 10 mph) to reduce the occurrence of <a href=\"https://crops.extension.iastate.edu/cropnews/2017/01/wind-speed-and-herbicide-application#:~:text=specify%2010%20MPH%20as%20the,spray%20pressure%2C%20etc.).\">spray drift</a>. Also, more mosquitoes tend to be caught in traps when wind speeds are lower. Spraying should be avoided above 86°F as the higher temperatures would cause pesticide droplets to <a href=\"https://grdc.com.au/__data/assets/pdf_file/0024/248181/GRDC-Weather-Essentials-for-Pesticide-Application-2017.pdf\">evaporate faster</a> than in cooler air. Results from the EDA showed that the virus is only prevalent during the months of July to September, and thus any efforts to reduce the mosquito population should be focused on this time period. \n",
    "\n",
    "We recommend that The Department of Public Health consider cost-friendly measures such as eliminating mosquito breeding grounds by covering up areas where water tends to collect and remain stagnant, e.g still ponds, flower pots, rainwater barrels, etc. preventing excessive breeding after periods of heavy rainfall. This is backed up by our EDA which shows an increase in WNV counts after a spike in the precipitation total. In addition, mosquito bites can also be reduced by using mosquito repellent, and wearing long pants and long-sleeves. \n",
    "\n",
    "Overall, our findings show that the benefits of increasing pesticide spraying may not outweigh the costs incurred. Therefore, we propose a combination of proactive (eg. spraying of pesticides)and reactive (eg. cover up mosquito breeding grounds) measures to combat the spread of the WNV in a more cost-efficient manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion  \n",
    "\n",
    "Our best performing model is SVM with a test accuracy score of 85.5%. Although accuracy provides an overview of the model's performance, we need to consider the other metrics to gain more meaningful insights to guide the decisions of the Chicago Department of Public Health. \n",
    "\n",
    "Other key metrics include the AUC, which shows that our model is 79.6% capable of distinguishing between WNV-positive and WNV-negative classes. We also note the recall rate which indicates that 80.7% of the actual WNV-positive cases were correctly classified. \n",
    "\n",
    "Based on these 3 metrics, we conclude that our model has performed relatively well in its classification of WNV-positive mosquitoes. This, in conjunction with the findings from the EDA and cost-benefit analysis, would help the Department of Public Health in making better decisions on when and where to spray pesticides to combat the spread of the WNV-virus. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
